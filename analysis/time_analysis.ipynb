{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/IPython/core/magics/osm.py:417: UserWarning: This is now an optional IPython functionality, setting dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/Robert/Code/Python/F1-ATPase-simulation\n"
     ]
    }
   ],
   "source": [
    "%cd ..\n",
    "import math\n",
    "import numpy as np\n",
    "import time\n",
    "import torch\n",
    "from typing import Any\n",
    "from archive.python.LangevinGillespie import LangevinGillespie\n",
    "from src.utils.compute_transition_matrix import compute_transition_matrix\n",
    "from src.core.cpp.f1sim import (\n",
    "    LangevinGillespie as LangevinGillespie_PybindWrap,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[m\u001b[m\u001b[1m\u001b[31mOS\u001b[m: \u001b[mDebian GNU/Linux 13 (trixie) x86_64\n",
      "\u001b[m\u001b[1m\u001b[31mKernel\u001b[m: \u001b[mLinux 6.6.87.2-microsoft-standard-WSL2\n",
      "\u001b[m\u001b[1m\u001b[31mCPU\u001b[m: \u001b[mAMD Ryzen 9 9950X (32) @ 4.30 GHz\n",
      "\u001b[m\u001b[1m\u001b[31mGPU 1\u001b[m: \u001b[mNVIDIA GeForce RTX 5080 (15.52 GiB) [Discrete]\n",
      "\u001b[m\u001b[1m\u001b[31mGPU 2\u001b[m: \u001b[mAMD Radeon(TM) Graphics (459.77 MiB) [Integrated]\n"
     ]
    }
   ],
   "source": [
    "!fastfetch --logo none --structure os:kernel:cpu:gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_simulation_params(LG):\n",
    "    LG.steps = 2000\n",
    "    LG.dt = 1e-6\n",
    "    LG.method = \"heun\"\n",
    "\n",
    "    # Mechanical / Thermal Setup\n",
    "    LG.kappa = 56\n",
    "    LG.kBT = 4.14\n",
    "    LG.gammaB = LG.computeGammaB(a=20, r=19, eta=1e-9)\n",
    "\n",
    "    # Multi State Setup\n",
    "    LG.theta_states = np.array([3, 36, 72, 116]) * math.pi / 180  # Deg â†’ Rad\n",
    "    LG.initial_state = 0  # Starting state\n",
    "\n",
    "    # Transition rate matrix\n",
    "    LG.transition_matrix = compute_transition_matrix(LG)\n",
    "\n",
    "\n",
    "def compute_simulation_time(obj: Any, n_steps: int, rng_seed: Any = None) -> float:\n",
    "    \"\"\"Run a simulation with n_steps on `obj` and return elapsed time in seconds.\"\"\"\n",
    "    obj.steps = n_steps\n",
    "    start_time = time.time()\n",
    "    obj.simulate(rng_seed)\n",
    "    return time.time() - start_time\n",
    "\n",
    "\n",
    "def run_simulations(LG, MAX_STEPS):\n",
    "    step_counts = list(range(1, MAX_STEPS + 1))\n",
    "    times = np.array([])\n",
    "\n",
    "    print(\"Running simulations...\")\n",
    "    for i, steps in enumerate(step_counts):\n",
    "        elapsed = compute_simulation_time(LG, steps, rng_seed=42)\n",
    "        times = np.append(times, elapsed)\n",
    "\n",
    "        print(f\"\\rStep {i}/{len(step_counts)}\", end=\"\", flush=True)\n",
    "\n",
    "    times_sum, times_mean = times.sum(), times.mean()\n",
    "    print(\"\\nSimulations complete!\")\n",
    "    print(f\"Total Time to compute {times_sum} seconds\")\n",
    "    print(f\"Average time to compute {times_mean} seconds\")\n",
    "    return times_sum, times_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch size: 100000, total batches: 1\n"
     ]
    }
   ],
   "source": [
    "# Initialize simulation wrapper\n",
    "LG_PybindWrap = LangevinGillespie_PybindWrap()\n",
    "initialize_simulation_params(LG_PybindWrap)\n",
    "\n",
    "N_SIMS = 100_000\n",
    "\n",
    "BYTES_PER_FLOAT = 4\n",
    "BYTES_PER_INT = 4\n",
    "TOTAL_FLOATS_PER_SIM = 3 * LG_PybindWrap.steps  # bead_positions, target_theta, etc.\n",
    "TOTAL_INTS_PER_SIM = LG_PybindWrap.steps  # states\n",
    "BYTES_PER_SIM = (\n",
    "    TOTAL_FLOATS_PER_SIM * BYTES_PER_FLOAT + TOTAL_INTS_PER_SIM * BYTES_PER_INT\n",
    ")\n",
    "\n",
    "# --- Dynamic GPU memory check ---\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    total_mem = torch.cuda.get_device_properties(0).total_memory\n",
    "    allocated = torch.cuda.memory_allocated(0)\n",
    "    reserved = torch.cuda.memory_reserved(0)\n",
    "    free_mem = total_mem - allocated - reserved\n",
    "\n",
    "    # Leave some room for other GPU usage\n",
    "    MAX_MEMORY_BYTES = int(free_mem * 0.5)\n",
    "else:\n",
    "    # fallback for CPU only\n",
    "    MAX_MEMORY_BYTES = 8 * 1024**3  # GB\n",
    "\n",
    "# Compute batch size\n",
    "BATCH_SIZE = max(1, min(N_SIMS, MAX_MEMORY_BYTES // BYTES_PER_SIM))\n",
    "total_batches = math.ceil(N_SIMS / BATCH_SIZE)\n",
    "\n",
    "print(f\"Batch size: {BATCH_SIZE}, total batches: {total_batches}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Note: If you use multi-threading, avoid using swap memory, instead employ batching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running batch 1/1: 100000 simulations\n",
      "Total time: 4.53 s\n"
     ]
    }
   ],
   "source": [
    "\n",
    "start_time = time.time()\n",
    "for batch_start in range(0, N_SIMS, BATCH_SIZE):\n",
    "    n_batch = min(BATCH_SIZE, N_SIMS - batch_start)\n",
    "    batch_num = batch_start // BATCH_SIZE + 1\n",
    "\n",
    "    print(f\"\\rRunning batch {batch_num}/{total_batches}: {n_batch} simulations\", end=\"\", flush=True)\n",
    "\n",
    "    # Run CUDA kernel\n",
    "    beads, states, thetas = LG_PybindWrap.simulate_multithreaded_cuda(n_batch)\n",
    "\n",
    "print(f\"\\nTotal time: {time.time() - start_time:.2f} s\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running batch 1/1: 100000 simulations"
     ]
    }
   ],
   "source": [
    "# start_time = time.time()\n",
    "# for batch_start in range(0, N_SIMS, BATCH_SIZE):\n",
    "#     n_batch = min(BATCH_SIZE, N_SIMS - batch_start)\n",
    "#     batch_num = batch_start // BATCH_SIZE + 1\n",
    "\n",
    "#     print(f\"\\rRunning batch {batch_num}/{total_batches}: {n_batch} simulations\", end=\"\", flush=True)\n",
    "\n",
    "#     beads, states, thetas = LG_PybindWrap.simulate_multithreaded(n_batch, 32)\n",
    "\n",
    "# print(f\"\\nTotal time: {time.time() - start_time:.2f} s\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# time1_total, time1_mean = run_simulations(LG_PybindWrap, MAX_STEPS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LG_Python = LangevinGillespie()\n",
    "# initialize_simulation_params(LG_Python)\n",
    "# time2_total, time2_mean = run_simulations(LG_Python, MAX_STEPS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(f\"The C++ wrap was {time2_total / time1_total:.2f} times faster than Python!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
