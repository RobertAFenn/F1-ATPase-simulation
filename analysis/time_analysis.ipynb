{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/Robert/Code/Python\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/IPython/core/magics/osm.py:417: UserWarning: This is now an optional IPython functionality, setting dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'f1sim'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01marchive\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mLangevinGillespie\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LangevinGillespie\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompute_transition_matrix\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m compute_transition_matrix\n\u001b[0;32m----> 9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mf1sim\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LangevinGillespie \u001b[38;5;28;01mas\u001b[39;00m LangevinGillespie_PybindWrap\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'f1sim'"
     ]
    }
   ],
   "source": [
    "%cd ..\n",
    "import math\n",
    "import numpy as np\n",
    "import time\n",
    "import torch\n",
    "from typing import Any\n",
    "from archive.python.LangevinGillespie import LangevinGillespie\n",
    "from src.utils.compute_transition_matrix import compute_transition_matrix\n",
    "from f1sim import LangevinGillespie as LangevinGillespie_PybindWrap\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!fastfetch --logo none --structure os:kernel:cpu:gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_simulation_params(LG):\n",
    "    LG.steps = 2000\n",
    "    LG.dt = 1e-6\n",
    "    LG.method = \"heun\"\n",
    "\n",
    "    # Mechanical / Thermal Setup\n",
    "    LG.kappa = 56\n",
    "    LG.kBT = 4.14\n",
    "    LG.gammaB = LG.computeGammaB(a=20, r=19, eta=1e-9)\n",
    "\n",
    "    # Multi State Setup\n",
    "    LG.theta_states = np.array([3, 36, 72, 116]) * math.pi / 180  # Deg â†’ Rad\n",
    "    LG.initial_state = 0  # Starting state\n",
    "\n",
    "    # Transition rate matrix\n",
    "    LG.transition_matrix = compute_transition_matrix(LG)\n",
    "\n",
    "\n",
    "def compute_simulation_time(obj: Any, n_steps: int, rng_seed: Any = None) -> float:\n",
    "    \"\"\"Run a simulation with n_steps on `obj` and return elapsed time in seconds.\"\"\"\n",
    "    obj.steps = n_steps\n",
    "    start_time = time.time()\n",
    "    obj.simulate(rng_seed)\n",
    "    return time.time() - start_time\n",
    "\n",
    "\n",
    "def run_simulations(LG, MAX_STEPS):\n",
    "    step_counts = list(range(1, MAX_STEPS + 1))\n",
    "    times = np.array([])\n",
    "\n",
    "    print(\"Running simulations...\")\n",
    "    for i, steps in enumerate(step_counts):\n",
    "        elapsed = compute_simulation_time(LG, steps, rng_seed=42)\n",
    "        times = np.append(times, elapsed)\n",
    "\n",
    "        print(f\"\\rStep {i}/{len(step_counts)}\", end=\"\", flush=True)\n",
    "\n",
    "    times_sum, times_mean = times.sum(), times.mean()\n",
    "    print(\"\\nSimulations complete!\")\n",
    "    print(f\"Total Time to compute {times_sum} seconds\")\n",
    "    print(f\"Average time to compute {times_mean} seconds\")\n",
    "    return times_sum, times_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize simulation wrapper\n",
    "LG_PybindWrap = LangevinGillespie_PybindWrap()\n",
    "initialize_simulation_params(LG_PybindWrap)\n",
    "\n",
    "N_SIMS = 100_000\n",
    "\n",
    "BYTES_PER_FLOAT = 4\n",
    "BYTES_PER_INT = 4\n",
    "TOTAL_FLOATS_PER_SIM = 3 * LG_PybindWrap.steps  # bead_positions, target_theta, etc.\n",
    "TOTAL_INTS_PER_SIM = LG_PybindWrap.steps  # states\n",
    "BYTES_PER_SIM = (\n",
    "    TOTAL_FLOATS_PER_SIM * BYTES_PER_FLOAT + TOTAL_INTS_PER_SIM * BYTES_PER_INT\n",
    ")\n",
    "\n",
    "# --- Dynamic GPU memory check ---\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    total_mem = torch.cuda.get_device_properties(0).total_memory\n",
    "    allocated = torch.cuda.memory_allocated(0)\n",
    "    reserved = torch.cuda.memory_reserved(0)\n",
    "    free_mem = total_mem - allocated - reserved\n",
    "\n",
    "    # Leave some room for other GPU usage\n",
    "    MAX_MEMORY_BYTES = int(free_mem * 0.5)\n",
    "else:\n",
    "    # fallback for CPU only\n",
    "    MAX_MEMORY_BYTES = 8 * 1024**3  # GB\n",
    "\n",
    "# Compute batch size\n",
    "BATCH_SIZE = max(1, min(N_SIMS, MAX_MEMORY_BYTES // BYTES_PER_SIM))\n",
    "total_batches = math.ceil(N_SIMS / BATCH_SIZE)\n",
    "\n",
    "print(f\"Batch size: {BATCH_SIZE}, total batches: {total_batches}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Note: If you use multi-threading, avoid using swap memory, instead employ batching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "start_time = time.time()\n",
    "for batch_start in range(0, N_SIMS, BATCH_SIZE):\n",
    "    n_batch = min(BATCH_SIZE, N_SIMS - batch_start)\n",
    "    batch_num = batch_start // BATCH_SIZE + 1\n",
    "\n",
    "    print(f\"\\rRunning batch {batch_num}/{total_batches}: {n_batch} simulations\", end=\"\", flush=True)\n",
    "\n",
    "    # Run CUDA kernel\n",
    "    beads, states, thetas = LG_PybindWrap.simulate_multithreaded_cuda(n_batch)\n",
    "\n",
    "print(f\"\\nTotal time: {time.time() - start_time:.2f} s\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start_time = time.time()\n",
    "# for batch_start in range(0, N_SIMS, BATCH_SIZE):\n",
    "#     n_batch = min(BATCH_SIZE, N_SIMS - batch_start)\n",
    "#     batch_num = batch_start // BATCH_SIZE + 1\n",
    "\n",
    "#     print(f\"\\rRunning batch {batch_num}/{total_batches}: {n_batch} simulations\", end=\"\", flush=True)\n",
    "\n",
    "#     beads, states, thetas = LG_PybindWrap.simulate_multithreaded(n_batch, 32)\n",
    "\n",
    "# print(f\"\\nTotal time: {time.time() - start_time:.2f} s\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# time1_total, time1_mean = run_simulations(LG_PybindWrap, MAX_STEPS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LG_Python = LangevinGillespie()\n",
    "# initialize_simulation_params(LG_Python)\n",
    "# time2_total, time2_mean = run_simulations(LG_Python, MAX_STEPS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(f\"The C++ wrap was {time2_total / time1_total:.2f} times faster than Python!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
